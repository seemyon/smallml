{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP-Based Prior Extraction\n",
    "\n",
    "**Goal:** Extract Bayesian priors (β₀, Σ₀) from trained CatBoost model using SHAP values\n",
    "\n",
    "This notebook implements **Algorithm 4.2** from Section 4.2.3 (Prior Distribution Extraction).\n",
    "\n",
    "## What We'll Do\n",
    "\n",
    "1. Load trained CatBoost model\n",
    "2. Compute SHAP values on validation set\n",
    "3. Extract prior means (β₀) from normalized SHAP values\n",
    "4. Compute prior variances (Σ₀) from cross-dataset heterogeneity\n",
    "5. Generate **Table 4.6** (Extracted Prior Distributions)\n",
    "6. Validate priors through predictive checks (**Table 4.7**)\n",
    "7. Save priors for hierarchical model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# SHAP for explainability\n",
    "import shap\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# SmallML framework\n",
    "from src.layer1_transfer.shap_extractor import SHAPPriorExtractor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained CatBoost model from Day 10\n",
    "model_path = '../models/transfer_learning/catboost_base.cbm'\n",
    "model = CatBoostClassifier()\n",
    "model.load_model(model_path)\n",
    "\n",
    "print(f\"✓ Model loaded: {model.tree_count_} trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data (for normalization statistics)\n",
    "X_train = pd.read_csv('../data/harmonized/X_train.csv')\n",
    "y_train = pd.read_csv('../data/harmonized/y_train.csv')['churned']\n",
    "\n",
    "print(f\"✓ Training data: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "X_val = pd.read_csv('../data/harmonized/X_val.csv')\n",
    "y_val = pd.read_csv('../data/harmonized/y_val.csv')['churned']\n",
    "\n",
    "print(f\"✓ Validation data: {X_val.shape[0]:,} samples, {X_val.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset source labels (need to recreate split from D_public_processed.csv)\n",
    "D_public = pd.read_csv('../data/harmonized/D_public_processed.csv')\n",
    "\n",
    "print(f\"✓ Full processed dataset: {D_public.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate split to extract dataset_source labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_full = D_public.drop(columns=['churned', 'dataset_source'])\n",
    "y_full = D_public['churned']\n",
    "dataset_source_full = D_public['dataset_source']\n",
    "\n",
    "# Same split as Day 9 (random_state=42)\n",
    "X_train_check, X_val_check, y_train_check, y_val_check, _, dataset_source_val = train_test_split(\n",
    "    X_full, y_full, dataset_source_full,\n",
    "    test_size=0.2,\n",
    "    stratify=y_full,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Verify split matches\n",
    "assert len(X_val_check) == len(X_val), \"Split mismatch!\"\n",
    "\n",
    "print(f\"✓ Dataset source labels extracted: {len(dataset_source_val):,} validation samples\")\n",
    "print(f\"  Dataset distribution:\")\n",
    "print(dataset_source_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize SHAP Prior Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize extractor with λ=1.0 (doubles empirical variance for conservatism)\n",
    "extractor = SHAPPriorExtractor(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    lambda_scale=1.0,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"✓ SHAPPriorExtractor initialized\")\n",
    "print(f\"  Features: {len(extractor.feature_names_)}\")\n",
    "print(f\"  Scaling factor: λ = {extractor.lambda_scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute SHAP Values (Algorithm 4.2, Step 1)\n",
    "\n",
    "**Note:** This step takes 10-20 minutes depending on your CPU. Go grab a coffee! ☕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values on validation set\n",
    "shap_values = extractor.compute_shap_values(X_val, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize SHAP Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot: Top 20 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_val,\n",
    "    max_display=20,\n",
    "    show=False\n",
    ")\n",
    "plt.title('SHAP Summary Plot: Top 20 Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/shap_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/figures/shap_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Prior Means (Algorithm 4.2, Steps 2-3)\n",
    "\n",
    "Transform SHAP values to coefficient-scale priors:\n",
    "- φ_j = mean(|SHAP_j|)\n",
    "- β₀_j = φ_j / std(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract prior means\n",
    "beta_0 = extractor.extract_prior_means(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prior Mean Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of prior means\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(beta_0, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "axes[0].set_xlabel('Prior Mean (β₀_j)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Prior Means', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Top 15 features by absolute value\n",
    "top_indices = np.argsort(np.abs(beta_0))[-15:][::-1]\n",
    "top_features = [extractor.feature_names_[i] for i in top_indices]\n",
    "top_values = beta_0[top_indices]\n",
    "\n",
    "colors = ['red' if v > 0 else 'blue' for v in top_values]\n",
    "axes[1].barh(range(len(top_features)), top_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_yticks(range(len(top_features)))\n",
    "axes[1].set_yticklabels(top_features, fontsize=10)\n",
    "axes[1].axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].set_xlabel('Prior Mean (β₀_j)', fontsize=12)\n",
    "axes[1].set_title('Top 15 Features by |β₀|', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3, axis='x')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/prior_means_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/figures/prior_means_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Prior Variances (Algorithm 4.2, Steps 4-6)\n",
    "\n",
    "Measure cross-dataset SHAP heterogeneity:\n",
    "- Compute dataset-specific SHAP: φ_j^(k) for k ∈ {telco, bank, ecomm}\n",
    "- Calculate variance: σ²_j = Var(φ_j^(1), φ_j^(2), φ_j^(3))\n",
    "- Apply scaling: Σ₀ = diag(σ²_j × (1 + λ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract prior variances\n",
    "Sigma_0 = extractor.extract_prior_variances(\n",
    "    X_val,\n",
    "    dataset_source_val,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Cross-Dataset Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-dataset SHAP for visualization\n",
    "datasets = dataset_source_val.unique()\n",
    "shap_by_dataset = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    mask = (dataset_source_val == dataset)\n",
    "    shap_by_dataset[dataset] = np.abs(shap_values[mask]).mean(axis=0)\n",
    "\n",
    "# Convert to DataFrame\n",
    "shap_df = pd.DataFrame(shap_by_dataset, index=extractor.feature_names_)\n",
    "\n",
    "# Plot variance across datasets for top 15 features\n",
    "prior_stds = np.sqrt(np.diag(Sigma_0))\n",
    "top_var_indices = np.argsort(prior_stds)[-15:][::-1]\n",
    "top_var_features = [extractor.feature_names_[i] for i in top_var_indices]\n",
    "\n",
    "shap_df_top = shap_df.loc[top_var_features]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "shap_df_top.plot(kind='barh', ax=ax, width=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Average |SHAP| per Dataset', fontsize=12)\n",
    "ax.set_ylabel('')\n",
    "ax.set_title('Cross-Dataset SHAP Variation (Top 15 Most Uncertain Features)', fontsize=13, fontweight='bold')\n",
    "ax.legend(title='Dataset', fontsize=10, title_fontsize=11)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/cross_dataset_variance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/figures/cross_dataset_variance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Table 4.6: Extracted Prior Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature importances from Table 4.4 (Day 10)\n",
    "table_4_4 = pd.read_csv('../results/tables/table_4_4.csv')\n",
    "print(\"Feature importances from Table 4.4:\")\n",
    "print(table_4_4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Table 4.6\n",
    "table_4_6 = extractor.generate_table_4_6(\n",
    "    top_n=5,\n",
    "    feature_importances=table_4_4\n",
    ")\n",
    "\n",
    "print(\"\\nTable 4.6: Extracted Prior Distributions for Top 5 Features\")\n",
    "print(\"=\"*80)\n",
    "print(table_4_6.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Table 4.6\n",
    "\n",
    "For each feature:\n",
    "- **Importance (w_j)**: CatBoost feature importance from Day 10\n",
    "- **Avg SHAP (φ_j)**: Average absolute SHAP value (feature effect magnitude)\n",
    "- **Prior Mean (β₀_j)**: Expected coefficient value for hierarchical model\n",
    "  - Positive → increases churn probability\n",
    "  - Negative → decreases churn probability\n",
    "- **Prior Std (√Σ₀_jj)**: Uncertainty in transferability\n",
    "  - Small → consistent effect across datasets (tight prior)\n",
    "  - Large → heterogeneous effect (diffuse prior, allows SME adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Table 4.6\n",
    "table_4_6.to_csv('../results/tables/table_4_6.csv', index=False)\n",
    "\n",
    "# Save as Markdown\n",
    "with open('../results/tables/table_4_6.md', 'w') as f:\n",
    "    f.write(\"# Table 4.6: Extracted Prior Distributions for Top 5 Features\\n\\n\")\n",
    "    f.write(table_4_6.to_markdown(index=False))\n",
    "    f.write(\"\\n\\n*Generated from SHAP values on validation set (Algorithm 4.2)*\\n\")\n",
    "\n",
    "print(\"✓ Table 4.6 saved to results/tables/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prior Predictive Check (Table 4.7)\n",
    "\n",
    "Validate prior quality by comparing:\n",
    "1. Random coefficients (baseline)\n",
    "2. Prior-only predictions (using β₀, Σ₀)\n",
    "3. Trained CatBoost (reference)\n",
    "\n",
    "**Expected:** Prior-only should outperform random but underperform full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prior predictive check\n",
    "results = extractor.prior_predictive_check(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_samples=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table 4.7\n",
    "table_4_7 = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Random coefficients β ~ N(0, 1)',\n",
    "        'AUC': results['random_coefficients'],\n",
    "        'Interpretation': 'Barely better than chance'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Prior-only β ~ N(β₀, Σ₀)',\n",
    "        'AUC': results['prior_only'],\n",
    "        'Interpretation': 'Substantial signal from transfer learning'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Fully-trained CatBoost',\n",
    "        'AUC': results['trained_catboost'],\n",
    "        'Interpretation': 'Full model performance'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nTable 4.7: Prior Predictive Performance on Validation Data\")\n",
    "print(\"=\"*80)\n",
    "print(table_4_7.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Table 4.7\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = ['Random\\nCoefficients', 'Prior-Only\\n(Transfer)', 'CatBoost\\n(Full Model)']\n",
    "aucs = [\n",
    "    results['random_coefficients'],\n",
    "    results['prior_only'],\n",
    "    results['trained_catboost']\n",
    "]\n",
    "colors = ['red', 'orange', 'green']\n",
    "\n",
    "bars = ax.bar(models, aucs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.set_ylabel('AUC-ROC', fontsize=13)\n",
    "ax.set_title('Prior Predictive Check: Model Comparison (Table 4.7)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0.4, 1.0])\n",
    "ax.axhline(0.5, color='gray', linestyle='--', linewidth=1, label='Random Guess')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, auc in zip(bars, aucs):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{auc:.4f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/prior_predictive_check.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/figures/prior_predictive_check.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Table 4.7\n",
    "table_4_7.to_csv('../results/tables/table_4_7.csv', index=False)\n",
    "\n",
    "# Save as Markdown\n",
    "with open('../results/tables/table_4_7.md', 'w') as f:\n",
    "    f.write(\"# Table 4.7: Prior Predictive Performance on Validation Data\\n\\n\")\n",
    "    f.write(table_4_7.to_markdown(index=False))\n",
    "    f.write(\"\\n\\n*Prior predictive check validates that extracted priors encode transferable knowledge.*\\n\")\n",
    "\n",
    "print(\"✓ Table 4.7 saved to results/tables/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Priors for Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save priors\n",
    "extractor.save_priors(\n",
    "    '../models/transfer_learning/priors.pkl',\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved priors\n",
    "loaded_priors = SHAPPriorExtractor.load_priors('../models/transfer_learning/priors.pkl')\n",
    "\n",
    "print(\"\\nSaved prior structure:\")\n",
    "print(f\"  - beta_0: {loaded_priors['beta_0'].shape}\")\n",
    "print(f\"  - Sigma_0: {loaded_priors['Sigma_0'].shape}\")\n",
    "print(f\"  - feature_names: {len(loaded_priors['feature_names'])} features\")\n",
    "print(f\"  - lambda_scale: {loaded_priors['lambda_scale']}\")\n",
    "if 'metadata' in loaded_priors:\n",
    "    print(f\"  - metadata: {list(loaded_priors['metadata'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPLETE: SHAP-Based Prior Extraction\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPrior Means (β₀):\")\n",
    "print(f\"  - Shape: {beta_0.shape}\")\n",
    "print(f\"  - Mean |β₀|: {np.abs(beta_0).mean():.4f}\")\n",
    "print(f\"  - Max |β₀|: {np.abs(beta_0).max():.4f}\")\n",
    "print(f\"  - Positive coefficients: {(beta_0 > 0).sum()}\")\n",
    "print(f\"  - Negative coefficients: {(beta_0 < 0).sum()}\")\n",
    "\n",
    "prior_stds = np.sqrt(np.diag(Sigma_0))\n",
    "print(f\"\\nPrior Covariance (Σ₀):\")\n",
    "print(f\"  - Shape: {Sigma_0.shape}\")\n",
    "print(f\"  - Mean σ₀: {prior_stds.mean():.4f}\")\n",
    "print(f\"  - Median σ₀: {np.median(prior_stds):.4f}\")\n",
    "print(f\"  - Max σ₀: {prior_stds.max():.4f}\")\n",
    "\n",
    "print(f\"\\nPrior Predictive Check:\")\n",
    "print(f\"  - Random AUC: {results['random_coefficients']:.4f}\")\n",
    "print(f\"  - Prior-only AUC: {results['prior_only']:.4f}\")\n",
    "print(f\"  - CatBoost AUC: {results['trained_catboost']:.4f}\")\n",
    "print(f\"  - Prior improvement: {results['prior_only'] - results['random_coefficients']:.4f}\")\n",
    "print(f\"  - Remaining gap: {results['trained_catboost'] - results['prior_only']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
